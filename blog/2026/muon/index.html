<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Muon and Manifold Versions | Jaisidh Singh </title> <meta name="author" content="Jaisidh Singh"> <meta name="description" content="A dive into Muon, manifold constraints, and optax."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/me.jpg?4ea4f62b15165b7e17cff5fc29aec32c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jaisidhsingh.github.io/blog/2026/muon/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jaisidh</span> Singh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Muon and Manifold Versions</h1> <p class="post-meta"> Created on January 24, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ml</a>   ·   <a href="/blog/category/optimisation"> <i class="fa-solid fa-tag fa-sm"></i> optimisation</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="tldr">TLDR</h1> <blockquote> <p>Muon is an adaptive optimizer specifically for 2D weight matrices that relies on a Newton-Schulz iteration to efficiently ensure that updates to the weight matrices are replaced with the nearest orthogonal matrix. Manifold Muon builds on Muon to constrain weights to the Steifel manifold, i.e., the manifold of matrices with unit condition number, to ensure that updates and matrices are well-conditioned.</p> <p>In this blog, we take a close look at Muon, try to understand it, and then move towards Manifold Muon. We cover all of the math required to implement and understand these optimizers, after which we will implement Manifold Muon in <code class="language-plaintext highlighter-rouge">optax</code>. This implementation will be used in a pull request to the official <code class="language-plaintext highlighter-rouge">optax</code> library to add Manifold Muon to the many optimizers in <code class="language-plaintext highlighter-rouge">optax</code>. Additionally, we do a tiny CIFAR-10 speed-run ourselves to see the improvements of Manifold Muon over the original.</p> </blockquote> <h1 id="muon">Muon</h1> <p>Muon is an adaptive optimizer designed by <a href="xxx">Keller Jordan</a> that has recently become quite popular, especially in the speed-running community of deep learning. What makes this optimizer special in comparison to the reigning champion <a href="decoupled%20optimisation">AdamW</a> is its emphasis on <em>orthogonality of updates</em>. More specifically, Muon searches for the nearest semi-orthogonal matrix to the update to a particular matrix, via something called a Newton-Schulz (NS) iteration. We’ll explain all of this precisely with the math below.</p> <h2 id="theory-and-design">Theory and Design</h2> <p>Before we begin understanding Muon in detail, a quick note: Muon only operates on 2D weight matrices. All scalar and vector parameters as well as the input and output layers (for e.g. the embedding look-up layer in transformers and the language modelling head) of a model should be optimized by AdamW and <em>not</em> Muon. For convolutional layers, it is possible to optimize them via Muon, however, the last 3 dimensions of the weight tensor must be collapsed into one dimension so that the resulting tensor is 2D.</p> <p>Now, given a weight matrix $\theta_{t-1} \in \mathbb{R}^{n\times m}$ at timestep $t$ of training, we compute its gradient w.r.t. the loss $\mathcal{L}$ as $g_t = \nabla_{\theta_{t-1}}\mathcal{L}(\theta_{t-1}), \ g_t \in \mathbb{R}^{n\times m}$. The weights $\theta$ are then updated to $\theta_{t+1}$ as</p> \[\theta_{t} = \theta_{t-1} - \eta \ u_t\] <p>where $\eta$ is the learning rate and $u_t \in \mathbb{R}^{n\times m}$ is the update that we compute as follows.</p> <ol> <li>Momentum $\mu$ is applied to the gradient as $m_t = \mu m_{t-1} + g_t, \ m_0 = 0$.</li> <li>Next, NS iteration on $m_t$ for $5$ steps finally yields the update $u_t$. The NS iteration is explained below.</li> </ol> <h3 id="newton-schulz-iteration">Newton-Schulz Iteration</h3> <p>The NS iteration is used to approximately orthogonalize the pre-update ($m_t$) by solving the constrained optimization problem</p> \[\operatorname{Orthogonalize}(X) = \arg\min_Z \| Z - X \|_F \qquad \text{s.t.} \qquad \text{either} \quad Z^\top Z = I \quad \text{or}\quad ZZ^\top = I\] <p>Note that the constraint specifies either $Z^\top Z = I$ or $ZZ^\top = I$. This makes the minimizer a <em>semi-orthogonal matrix</em> and equivalently means that if the singular value decomposition (SVD) of $X$ is $U\Sigma V^\top$, then the SVD of $\operatorname{Orthogonalize}(X)$ will be $UV^\top$ (the matrix of singular values $\Sigma$ of the semi-orthogonal matrix is just the identity matrix $I$). Having established this, we now show the NS iteration algorithm below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ns_iteration</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">x</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">"</span><span class="s">Wrong no. of dimensions in input</span><span class="sh">"</span>
  <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="mf">3.4445</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.7750</span><span class="p">,</span> <span class="mf">2.0315</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">norm</span><span class="p">()</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
  
  <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">T</span>
  
  <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">y</span> <span class="o">@</span> <span class="n">y</span><span class="p">.</span><span class="n">T</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">A</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="n">A</span> <span class="o">@</span> <span class="n">A</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="n">B</span> <span class="o">@</span> <span class="n">y</span>
  
  <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">T</span>
  
  <span class="k">return</span> <span class="n">y</span>
</code></pre></div></div> <p>Let us write one step of this iteration to gain a better understanding of why it orthogonalizes its input. Let $X \in \mathbb{R}^{p\times q}$ be the input matrix. Then,</p> \[Z = aX + b(XX^\top)X + c(XX^\top)^2X\] \[=(aI + bXX^\top + c (XX^\top)^2)X\] <p>Now substituting the SVD of $X$ as $U\Sigma V^\top$, we get</p> \[=(a\cdot I + b\cdot U\Sigma^2 U^\top + c\cdot U\Sigma^4 U)U\Sigma V^\top\] \[=U(a\cdot\Sigma +b\cdot\Sigma^3 + c\cdot\Sigma^5 )V^\top\] <p>Clearly, one step of the NS iteration yields a matrix whose singular values are a quintic ($5^{\text{th}}$ order with only odd powers) polynomial $\rho(x) = ax + bx^3 + cx^5$. Applying this iteration for $T$ steps would then apply the polynomial $T$ times (we denote this by $\rho^T(x)$) on the singular values. Since the singular values all lie in $[0, 1]$ due to the normalization of the input, we then only need to choose the polynomial coefficients such that as $T \to \infty, \rho^T(x) \to 1 \ \forall x \in [0, 1]$. This would make all singular values of the resultant matrix tend to $1$, thereby making it orthogonal.</p> <p>That’s it! Choosing good coefficients of the polynomials gets us to an appreciably fast iteration, where the following constraints must be kept in mind while choosing them:</p> <ol> <li>$a$ must be large as $\rho’(0)=a$. This implies that $a$ controls the rate of convergence for small initial singular values.</li> <li>For every $x \in [0, 1]$ we want to converge to the singular value interval $[1-\epsilon, 1+\epsilon]$ for some $\epsilon &gt; 0$ as $T \to \infty$ so that the result of the NS iteration is not far from its input.</li> </ol> <p>While one can experiment with different ways to solve this optimization problem, the creator of Muon arrives at the ones given in the algorithm-code-block by employing a post-hoc gradient-based approach.</p> <h2 id="cifar-10-speedrun">CIFAR-10 speedrun</h2> <p>asdf</p> <h1 id="manifold-muon">Manifold Muon</h1> <h2 id="theory-and-design-1">Theory and design</h2> <p>asdf</p> <h2 id="optax-implementation">Optax implementation</h2> <p>asdf</p> <h2 id="cifar-10-speedrun-1">CIFAR-10 speedrun</h2> <p>asdf</p> <h1 id="references">References</h1> <ol> <li><a href="https://thinkingmachines.ai/blog/modular-manifolds" rel="external nofollow noopener" target="_blank">Thinking Machines’ Manifold Muon blog</a></li> <li><a href="https://sdbuchanan.com/blog/manifold-muon/" rel="external nofollow noopener" target="_blank">Sam D. Buchanan’s blog</a></li> <li><a href="https://kellerjordan.github.io/posts/muon/" rel="external nofollow noopener" target="_blank">Keller Jordan’s blog</a></li> <li><a href="https://github.com/KellerJordan/Muon" rel="external nofollow noopener" target="_blank">Keller Jordan’s Muon GitHub repo</a></li> <li><a href="https://github.com/google-deepmind/optax/blob/main/optax/contrib/__init__.py" rel="external nofollow noopener" target="_blank">Google DeepMind’s Optax GitHub repo</a></li> <li><a href="https://github.com/thinking-machines-lab/manifolds/tree/main" rel="external nofollow noopener" target="_blank">Thinking Machine’s Manifolds GitHub repo</a></li> </ol> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/grokking/">Grokking fast and slow</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/celebration/">Celebration is the secret</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/uspb3/">Ultra-Scale Playbook vol-3 - DeepSpeed ZeRO</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/uspb2/">Ultra-Scale Playbook vol-2 - Data Parallelism</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/uspb1/">Ultra-Scale Playbook vol-1 - Single GPU</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2026 Jaisidh Singh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>