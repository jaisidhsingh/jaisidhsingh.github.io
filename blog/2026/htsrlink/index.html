<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Simple Toy Model to Bridge HTSR with Alpha-REQ | Jaisidh Singh </title> <meta name="author" content="Jaisidh Singh"> <meta name="description" content="Bounding conditioning of features with that of weights"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/me.jpg?4ea4f62b15165b7e17cff5fc29aec32c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jaisidhsingh.github.io/blog/2026/htsrlink/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jaisidh</span> Singh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">A Simple Toy Model to Bridge HTSR with Alpha-REQ</h1> <p class="post-meta"> Created on February 10, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ml</a>   ·   <a href="/blog/category/ml"> <i class="fa-solid fa-tag fa-sm"></i> ml</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="tldr">TLDR</h2> <blockquote> <p>Generalization in neural networks has been shown to be correlated with one phenomenon expressed in two venues: how strongly singular values decay in (i) weights (Martin and Mahoney’s HTSR theory) and (ii) features (Agarwal’s $\alpha$-REQ). This blog connects the two approaches for toy linear models to show how HTSR may give rise to $\alpha$-REQ.</p> </blockquote> <h2 id="introduction">Introduction</h2> <p>Recent advances in deep learning theory have used spectral analysis as a tool to study generalization of neural networks. On one hand, we have Heavy-Tailed Self-Regularization (HTSR) theory, which analyzes a network’s weights to demonstrate that in well-trained networks, singular values of weights follow a power-law decay. On the other hand, $\alpha$-ReQ analyzes activations or features to show that high-quality representations also follow a specific spectral decay that correlates with generalization.</p> <p>While the two approaches are proposed and used separately, it is plain that properties of weights and features are coupled by design. Hence, this post explores the connection between HTSR and $\alpha$-REQ through fundamental linear algebra on a toy linear model $Y = XW$.</p> <ol> <li>First, we will quickly relate the condition number of a matrix to the decay of the singular values.</li> <li>Then we will use our linear model to look at how the singular value decay/conditioning of the weights $W$ can impact the features $Y$.</li> </ol> <p>The result in this post is mainly a corollary of those in the vast literature on signal propagation in neural networks. Our aim here is to simply yet mathematically relate two interesting emergences of geometry in distinct spaces, i.e., weights and features.</p> <h2 id="linking-singular-value-decay-to-condition-number">Linking singular value decay to condition number</h2> <p>Intuitively, one can see that a steeper decay in the singular value spectrum of a matrix should correspond to a higher condition number and vice versa, as a flatter spectrum implies that the minimum singular value is still reasonably close to the maximum singular value. Let us prove this formally.</p> <p>We start with a matrix $A \in \mathbb{R}^{n \times m}$ that has full rank, i.e., $A^T A$ is symmetric and positive semi-definite (PSD). Then, we can write the condition number of $A$ as</p> \[\kappa(A) = \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)} = \frac{\sqrt{\lambda_{\max}(A^T A)}}{\sqrt{\lambda_{\min}(A^T A)}}\] <p>Then, assuming that the eigenvalues of $A^T A$ follow a powerlaw such that $\lambda = c_0 u^{-\alpha}$ where $u$ is a scalar and $c_0$ is a fixed constant, we can write</p> \[\lambda_{\max} = c_0 (u_{\max})^{-\alpha} \quad \text{and} \quad \lambda_{\min} = c_0 (u_{\min})^{-\alpha}\] <p>Since $u_{\min} = m \ u_{\max}$, we can substitute this in the expression for $\kappa(A)$ to find</p> \[\kappa(A) = \frac{\lambda_{\max}}{\lambda_{\min}} = \frac{c_0 (u_{\min})^{-\alpha}}{c_0 (m u_{\max})^{-\alpha}} = m^{\alpha}\] <p>This result confirms our intuition: how fast the singular value spectrum of $A$ decays is exponentially proportional to the $\kappa(A)$. Accordingly, this result will let us connect HTSR with $\alpha$-REQ cleanly in the following.</p> <h2 id="toy-model-to-bridge-htsr-and-alpha-req">Toy model to bridge HTSR and $\alpha$-REQ</h2> <p>Given a data matrix $X \in \mathbb{R}^{n \times d}$, where $n$ is the number of data points ad $d$ is the dimension of each sample’s features, we are interested in a linear transform of $X$ by weights $W \in \mathbb{R}^{d \times m}$ to compute $Y \in \mathbb{R}^{n \times m}$ as</p> \[Y = X W\] <p>According to HTSR theory, the powerlaw fit of the decay of singular values of $W$ should reduce as the weights are updated throughout training, and $\alpha$-REQ shows how the same happens for features $Y$. We will now derive a link between the two observations.</p> <p>For any two compatible matrices $A$ and $B$, the condition number of their matrix multiplication is bounded as</p> \[\kappa(AB) \leq \kappa(A) \cdot \kappa(B)\] <p>This result simply follows from the nice properties of singular values: given some singular values arranged in descending order like $\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_N \geq 0$, we have for $A$ and $B$</p> \[\sigma_N(A)\sigma_i(B) \leq \sigma_i(AB) \leq \sigma_1(A)\sigma_i(B) \quad i=1,2,\dots,N\] <p>Corresondingly, $\sigma_{\max}(AB) \leq \sigma_{\max}(A) \ \sigma_{\max}(B)$ and $\sigma_{\text{min}}(AB) \geq \sigma_{\text{min}}(A) \ \sigma_{\text{min}}(B)$ give the above result for the condition number of a matrix multiplication. Then, we can see that</p> \[\kappa(Y) \leq \kappa(X) \cdot \kappa(W) = C_{\text{data}} \cdot \kappa(W)\] <p>Here $\kappa(X)$ is denoted by a fixed scalar $C_{\text{data}}$ that assumes the data matrix to be of full rank and fixed. Finally, using the relationship between condition number and powerlaw fit coefficient for singular value decay, we can see the bound</p> \[c_{Y} \cdot m^{\alpha_Y} \leq (C_{\text{data}} \cdot c_{W}) \cdot m^{\alpha_W} \implies m^{\alpha_Y} \leq \frac{C_{\text{data}} \cdot c_{W}}{c_{Y}} \cdot m^{\alpha_W}\] <p>This shows that as the powerlaw fit of the singular value decay $\alpha_W$ for weights $W$ reduces, so should the maximum value of the corresponding powerlaw fit $\alpha_Y$ for features $Y$.</p> <h2 id="discussion">Discussion</h2> <p>What happens when the $\kappa(X)$ is not stationary? This is precisely the case for deep neural networks, as the inputs to the linear projection evolve due to non-linear activation functions and due to cross-activation interactions during training. While one can continually substitute the fixed condition number of the inputs to the neural network, non-linearities complicate analytical expressions of the relationship of HTSR and $\alpha$-REQ.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/muon/">Muon and Manifold Versions</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/grokking/">Grokking fast and slow</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/celebration/">Celebration is the secret</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/hypernets/">New POVs on hypernetworks</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2026 Jaisidh Singh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>